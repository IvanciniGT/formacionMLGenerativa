{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Verificar la disponibilidad de la GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Crear un directorio para almacenar las imágenes generadas\n",
    "os.makedirs('gan_images', exist_ok=True)\n",
    "\n",
    "# Configuración de parámetros\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "batch_size = 64\n",
    "\n",
    "# Definir la arquitectura del generador\n",
    "generator = nn.Sequential( # Parte de una imagen de tamaño 10x10(=100) cuyos pixels contienen datos al azar\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784), # Y genera una imagen de tamaño 28x28(784) cuyos pixxels deben tener valoresd qwue se asemejen a los de las fotos de nuestra librería MNIST\n",
    "            nn.Tanh()\n",
    ").to(device)\n",
    "\n",
    "# Definir la arquitectura del discriminador\n",
    "discriminator = nn.Sequential(\n",
    "            nn.Linear(784, 1024), # Partimos de una iogamen de 28x28 (generada por el generador o una imagen real del mnist)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), # Esto hace que en las distintas iteraciones, se supriman aletaoriamente un 30% de las neuronas... Evita que haya neuronas que se usen demasiado... haciendo que otras neoronas no aprendan\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1), # Acabamos con un dato -> Si la imagen es buena o no\n",
    "            nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "# Cargar y preprocesar los datos MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(dataset=mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Inicializar los optimizadores. Esta es la función que trata de identificar el mínimo en la función de error (pérdida)\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Función de pérdida. Esta función mira básicamente en cuantas se ha equivocado el discriminador al discriminar entre las imágenes reales y las autogeneradas\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Entrenamiento de la GAN\n",
    "num_epochs = 60\n",
    "for epoch in range(num_epochs):\n",
    "    for real_images, _ in data_loader: # Aquí es donde se aplcia el batch_size (leemos las imágenes de 64 en 64)\n",
    "        # Insuflar al discrimiador imágenes REALES\n",
    "        real_images = real_images.view(-1, image_size).to(device) # Saco un paquete de imágenes y las coloco en el dispositivo (RAM asociada a la CPU, o en la RAM de la GPU)\n",
    "        real_labels = torch.ones(real_images.size(0), 1).to(device) # Generado datos (Y) para esas imágenes. 1 significa que la imagen es REAL (sacada del mnist)\n",
    "        optimizer_discriminator.zero_grad() # Resetear el optimizador para comenzar a calcular los valores que minimizan la función de pérdida\n",
    "        outputs = discriminator(real_images) # Discrima las imágenes reales: Generamos la estimación del DISCRIMINADOR (en el caso ideal, un discriminador perfecto, para todas debería devolver 1)\n",
    "        loss_real = criterion(outputs, real_labels) # Calculan la función de pérdida para estos datos... Es decir... en cuantas se ha equivocado el discriminador\n",
    "        loss_real.backward()  # Recálculo de los párametros\n",
    "        \n",
    "        # Insuflamos al discriminador imágenes que provienen del generador\n",
    "\n",
    "        ## Generar imágenes por el GENERADOR, partiendo de RUIDO !\n",
    "        noise = torch.randn(real_images.size(0), latent_dim).to(device) # Tantas imágenes como se hayan procesado reales (64)... de tamaño 100 pixels... llenas de ruido (números aleatorios)\n",
    "        fake_images = generator(noise) # Y se las pasamos al generador... para que genere imágenes de tamaño 28x28, parecidas a las del mnist... o no!\n",
    "        fake_labels = torch.zeros(real_images.size(0), 1).to(device) # Generado datos (Y) para esas imágenes. 0 significa que la imagen es NO REAL (no está sacada del mnist) \n",
    "\n",
    "        outputs = discriminator(fake_images.detach()) # Le pongo al disciminador a discriminar entre las que ha generado el GENERADOR ( si fuera un discriminador perfecto, todas darían 0)\n",
    "        loss_fake = criterion(outputs, fake_labels) # Cálculo la función de pérdidas... Es decir, miro en cuántas se ha equivocado el discriminador\n",
    "        loss_fake.backward() # Que aplicamos para hacer un recálculo de los parámetros\n",
    "\n",
    "        optimizer_discriminator.step() # De ahora en adelante, hacemos que el discriminador trabaje con esos nuevos parámetros\n",
    "\n",
    "        # Vamos a mejorar el generador ( ya con el discriminador mejorado)\n",
    "        optimizer_generator.zero_grad()  # Lo inicializo\n",
    "        outputs = discriminator(fake_images)  # Discrima los datos fake\n",
    "        loss_generator = criterion(outputs, real_labels) # Y tendré nuevas equivocaciones (alguna menos)\n",
    "        loss_generator.backward() # Y con esas pérdidas, recalculo los parámetros del generador\n",
    "\n",
    "        optimizer_generator.step()  # Y le aplico esos parámetros para la siguiente tanda de imágenes.\n",
    "\n",
    "    # Generar unas cuantas imágenes, para ver con nuestros ojitos que tal se comporta el generador!\n",
    "    with torch.no_grad():\n",
    "        target_digit = 7\n",
    "        noise = torch.randn(16, latent_dim).to(device) # Genera 16 imágenes de 10x10 con ruido\n",
    "        #noise[:, target_digit] = 2.0\n",
    "        generated_images = generator(noise).cpu().detach() # Y se las pasamos al generador\n",
    "\n",
    "    # Imprimirlas por pantalla... a ver cómo le fue\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(15, 3))\n",
    "    for i in range(2):\n",
    "        for j in range(8):\n",
    "            axes[i, j].imshow(generated_images[i * 8 + j].view(28, 28), cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "    plt.savefig(f'gan_images/epoch_{epoch + 1}_digit_{target_digit}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
